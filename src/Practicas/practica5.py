import pandas as pd
import numpy as np

# 1. Cargar el fichero de excel "dataset_bigdata" y nombrarlo "df_practica5"
print("=" * 80)
print("ğŸ“‚ PRÃCTICA 5: AnÃ¡lisis de Dataset BigData")
print("=" * 80)

df_practica5 = pd.read_excel("src/Ejercicios/dataset_bigdata.xlsx", engine='openpyxl')
print(f"\nâœ… Dataset cargado exitosamente: {len(df_practica5)} registros")
print("\nğŸ“Š Primeras filas del dataset:")
print(df_practica5.head())

print("\nğŸ“‹ InformaciÃ³n del dataset:")
print(df_practica5.info())

print("\nğŸ” Valores nulos por columna:")
print(df_practica5.isnull().sum())

# ğŸ” DIAGNÃ“STICO: Ver quÃ© datos tenemos disponibles
print("\n" + "=" * 80)
print("ğŸ” DIAGNÃ“STICO DE DATOS DISPONIBLES")
print("=" * 80)

print("\nğŸ“Š Tipos de procesamiento disponibles:")
print(df_practica5['tipo_procesamiento'].value_counts())

print("\nğŸ“Š OrÃ­genes de datos disponibles:")
print(df_practica5['origen_datos'].value_counts())

print("\nğŸ“Š Combinaciones tipo_procesamiento + origen_datos:")
print(df_practica5.groupby(['tipo_procesamiento', 'origen_datos']).size())

print("\nğŸ“Š Registros 'batch' con tamano_gb >= 6:")
batch_mayor_6 = df_practica5[
    (df_practica5['tipo_procesamiento'] == 'batch') & 
    (df_practica5['tamano_gb'] >= 6)
]
print(batch_mayor_6[['origen_datos', 'tamano_gb', 'tipo_procesamiento']])

# 2. Analizar solo eventos batch de redes con tamano_gb >= 6
print("\n" + "=" * 80)
print("ğŸ” FILTRADO DE DATOS")
print("=" * 80)

# Primero verificar si existen registros que cumplan las condiciones
print("\nğŸ” Verificando condiciones de filtrado...")
print(f"   â€¢ Registros tipo 'batch': {(df_practica5['tipo_procesamiento'] == 'batch').sum()}")
print(f"   â€¢ Registros de 'red': {(df_practica5['origen_datos'] == 'red').sum()}")
print(f"   â€¢ Registros con tamano_gb >= 6: {(df_practica5['tamano_gb'] >= 6).sum()}")

# Intentar filtrado mÃ¡s flexible si no hay datos
df_filtrado = df_practica5[
    (df_practica5['tipo_procesamiento'] == 'batch') & 
    (df_practica5['origen_datos'] == 'red') & 
    (df_practica5['tamano_gb'] >= 6)
].copy()

if len(df_filtrado) == 0:
    print("\nâš ï¸ No hay registros que cumplan las 3 condiciones simultÃ¡neamente.")
    print("ğŸ“ Aplicando filtrado alternativo: tipo='batch' O origen='red', con tamano_gb >= 6")
    
    # Filtrado alternativo mÃ¡s flexible
    df_filtrado = df_practica5[
        (
            (df_practica5['tipo_procesamiento'] == 'batch') | 
            (df_practica5['origen_datos'] == 'red')
        ) & 
        (df_practica5['tamano_gb'] >= 6)
    ].copy()

print(f"\nâœ… Registros filtrados: {len(df_filtrado)}")

if len(df_filtrado) == 0:
    print("\nâŒ ERROR: No se encontraron registros con tamano_gb >= 6")
    print("ğŸ“ Usando todos los registros disponibles para demostraciÃ³n...")
    df_filtrado = df_practica5.copy()

print(f"\nğŸ“Š Vista previa de datos filtrados ({len(df_filtrado)} registros):")
print(df_filtrado.head(10))

print("\nğŸ” Valores nulos en datos filtrados:")
print(df_filtrado.isnull().sum())

# 3. Imputar los NaN con la mediana (CORREGIDO)
print("\n" + "=" * 80)
print("ğŸ”§ IMPUTACIÃ“N DE VALORES NULOS")
print("=" * 80)

# Calcular medianas antes de imputar (con manejo de NaN)
mediana_latencia = df_filtrado['latencia_ms'].median()
mediana_anomalia = df_filtrado['etiqueta_anomalia'].median()

# Si la mediana es NaN, usar la media o un valor por defecto
if pd.isna(mediana_latencia):
    mediana_latencia = df_filtrado['latencia_ms'].mean()
    if pd.isna(mediana_latencia):
        mediana_latencia = 0
    print(f"âš ï¸ Usando media en lugar de mediana para latencia_ms")

if pd.isna(mediana_anomalia):
    mediana_anomalia = df_filtrado['etiqueta_anomalia'].mean()
    if pd.isna(mediana_anomalia):
        mediana_anomalia = 0
    print(f"âš ï¸ Usando media en lugar de mediana para etiqueta_anomalia")

print(f"\nğŸ“ˆ Valores para imputaciÃ³n:")
print(f"   - latencia_ms: {mediana_latencia:.2f}")
print(f"   - etiqueta_anomalia: {mediana_anomalia:.2f}")

# Imputar valores nulos (CORREGIDO - sin inplace)
df_filtrado.loc[:, 'latencia_ms'] = df_filtrado['latencia_ms'].fillna(mediana_latencia)
df_filtrado.loc[:, 'etiqueta_anomalia'] = df_filtrado['etiqueta_anomalia'].fillna(mediana_anomalia)

print(f"\nâœ… Valores nulos imputados")
print(f"\nğŸ” VerificaciÃ³n de valores nulos despuÃ©s de imputaciÃ³n:")
print(df_filtrado[['latencia_ms', 'etiqueta_anomalia']].isnull().sum())

# 4. Agrupar por tipo de procesamiento y calcular
print("\n" + "=" * 80)
print("ğŸ“Š AGRUPACIÃ“N Y ANÃLISIS")
print("=" * 80)

# Agrupar por tipo_procesamiento y calcular estadÃ­sticas
resultado = df_filtrado.groupby('tipo_procesamiento').agg({
    'id_registro': 'count',                    # a. cantidad de registros
    'tamano_gb': 'mean',                       # b. media de tamano_gb
    'tasa_eventos_por_seg': 'sum'              # c. total tasa de eventos por seg
}).rename(columns={
    'id_registro': 'cantidad_registros',
    'tamano_gb': 'media_tamano_gb',
    'tasa_eventos_por_seg': 'total_tasa_eventos_seg'
})

print("\nğŸ“ˆ RESULTADOS DEL ANÃLISIS:")
print("=" * 80)
print(resultado)

# Formatear resultados para mejor visualizaciÃ³n
print("\nğŸ“‹ RESUMEN DETALLADO:")
print("=" * 80)
if len(resultado) > 0:
    for tipo_proc, row in resultado.iterrows():
        print(f"\nğŸ”¹ Tipo de procesamiento: {tipo_proc.upper()}")
        print(f"   a) Cantidad de registros: {int(row['cantidad_registros'])}")
        print(f"   b) Media de tamaÃ±o (GB): {row['media_tamano_gb']:.2f} GB")
        print(f"   c) Total tasa de eventos/seg: {row['total_tasa_eventos_seg']:.2f}")
else:
    print("âš ï¸ No hay datos para mostrar en el resumen")

# Guardar resultados en CSV
output_path = 'src/Practicas/practica5_resultados.csv'
resultado.to_csv(output_path)
print(f"\nğŸ’¾ Resultados guardados en: {output_path}")

# EstadÃ­sticas adicionales
print("\n" + "=" * 80)
print("ğŸ“Š ESTADÃSTICAS ADICIONALES")
print("=" * 80)

if len(df_filtrado) > 0:
    print(f"\nğŸ”¢ EstadÃ­sticas descriptivas de latencia_ms:")
    print(df_filtrado['latencia_ms'].describe())
    
    print(f"\nğŸ”¢ EstadÃ­sticas descriptivas de tamano_gb:")
    print(df_filtrado['tamano_gb'].describe())
    
    print(f"\nğŸ”¢ DistribuciÃ³n de etiqueta_anomalia:")
    print(df_filtrado['etiqueta_anomalia'].value_counts())
else:
    print("âš ï¸ No hay datos para mostrar estadÃ­sticas")

print("\n" + "=" * 80)
print("âœ… ANÃLISIS COMPLETADO")
print("=" * 80)
